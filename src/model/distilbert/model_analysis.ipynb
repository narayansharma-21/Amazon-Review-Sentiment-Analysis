{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, mean_absolute_error, roc_auc_score, \\\n",
    "    classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "def getDF(path):\n",
    "  df = {}\n",
    "  for i, d in enumerate(parse(path)):\n",
    "    df[i] = d\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('../../../data/raw/AMAZON_FASHION.json.gz')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   overall  verified   reviewTime      reviewerID        asin  reviewerName  \\\n0      5.0      True  10 20, 2014  A1D4G1SNUZWQOT  7106116521         Tracy   \n1      2.0      True  09 28, 2014  A3DDWDH9PX2YX2  7106116521     Sonja Lau   \n2      4.0     False  08 25, 2014  A2MWC41EW7XL15  7106116521      Kathleen   \n3      2.0      True  08 24, 2014  A2UH2QQ275NV45  7106116521   Jodi Stoner   \n4      3.0     False  07 27, 2014   A89F3LQADZBS5  7106116521  Alexander D.   \n\n                                          reviewText  \\\n0                             Exactly what I needed.   \n1  I agree with the other review, the opening is ...   \n2  Love these... I am going to order another pack...   \n3                                too tiny an opening   \n4                                               Okay   \n\n                                             summary  unixReviewTime vote  \\\n0                             perfect replacements!!      1413763200  NaN   \n1  I agree with the other review, the opening is ...      1411862400    3   \n2                                My New 'Friends' !!      1408924800  NaN   \n3                                          Two Stars      1408838400  NaN   \n4                                        Three Stars      1406419200  NaN   \n\n  style image  overallInt                                         reviewFull  \n0   NaN   NaN           5                             Exactly what I needed.  \n1   NaN   NaN           2  I agree with the other review, the opening is ...  \n2   NaN   NaN           4  Love these... I am going to order another pack...  \n3   NaN   NaN           2                                too tiny an opening  \n4   NaN   NaN           3                                               Okay  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>verified</th>\n      <th>reviewTime</th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>reviewerName</th>\n      <th>reviewText</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>vote</th>\n      <th>style</th>\n      <th>image</th>\n      <th>overallInt</th>\n      <th>reviewFull</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>10 20, 2014</td>\n      <td>A1D4G1SNUZWQOT</td>\n      <td>7106116521</td>\n      <td>Tracy</td>\n      <td>Exactly what I needed.</td>\n      <td>perfect replacements!!</td>\n      <td>1413763200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>Exactly what I needed.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.0</td>\n      <td>True</td>\n      <td>09 28, 2014</td>\n      <td>A3DDWDH9PX2YX2</td>\n      <td>7106116521</td>\n      <td>Sonja Lau</td>\n      <td>I agree with the other review, the opening is ...</td>\n      <td>I agree with the other review, the opening is ...</td>\n      <td>1411862400</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>I agree with the other review, the opening is ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.0</td>\n      <td>False</td>\n      <td>08 25, 2014</td>\n      <td>A2MWC41EW7XL15</td>\n      <td>7106116521</td>\n      <td>Kathleen</td>\n      <td>Love these... I am going to order another pack...</td>\n      <td>My New 'Friends' !!</td>\n      <td>1408924800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>Love these... I am going to order another pack...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2.0</td>\n      <td>True</td>\n      <td>08 24, 2014</td>\n      <td>A2UH2QQ275NV45</td>\n      <td>7106116521</td>\n      <td>Jodi Stoner</td>\n      <td>too tiny an opening</td>\n      <td>Two Stars</td>\n      <td>1408838400</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>too tiny an opening</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.0</td>\n      <td>False</td>\n      <td>07 27, 2014</td>\n      <td>A89F3LQADZBS5</td>\n      <td>7106116521</td>\n      <td>Alexander D.</td>\n      <td>Okay</td>\n      <td>Three Stars</td>\n      <td>1406419200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>Okay</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop reviews with no reviewText since we are primarily interested in analyzing review text\n",
    "df = df.dropna(subset=['reviewText'])\n",
    "\n",
    "df['overallInt'] = df['overall'].astype(int)\n",
    "df['reviewText'] = df['reviewText'].astype(str)\n",
    "df['reviewFull'] = df['reviewText']\n",
    "df['reviewFull'] = df['reviewFull'].astype(str)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                          reviewText  overall  overallInt  \\\n0                             Exactly what I needed.      4.0           4   \n1  I agree with the other review, the opening is ...      1.0           1   \n2  Love these... I am going to order another pack...      3.0           3   \n3                                too tiny an opening      1.0           1   \n4                                               Okay      2.0           2   \n\n                                          reviewFull  \n0                             Exactly what I needed.  \n1  I agree with the other review, the opening is ...  \n2  Love these... I am going to order another pack...  \n3                                too tiny an opening  \n4                                               Okay  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reviewText</th>\n      <th>overall</th>\n      <th>overallInt</th>\n      <th>reviewFull</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Exactly what I needed.</td>\n      <td>4.0</td>\n      <td>4</td>\n      <td>Exactly what I needed.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I agree with the other review, the opening is ...</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>I agree with the other review, the opening is ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Love these... I am going to order another pack...</td>\n      <td>3.0</td>\n      <td>3</td>\n      <td>Love these... I am going to order another pack...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>too tiny an opening</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>too tiny an opening</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Okay</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>Okay</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep relevant columns\n",
    "df = df[['reviewText', 'overall', 'overallInt', 'reviewFull']]\n",
    "df['overallInt'] = df['overallInt'].apply(lambda x: x - 1)\n",
    "df['overall'] = df['overall'].apply(lambda x: x - 1)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(df_train)\n",
    "test_dataset = Dataset.from_pandas(df_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\anaconda3\\envs\\rss-hw4\\lib\\site-packages\\transformers\\configuration_utils.py:336: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/705922 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb74a36624d141d2a3f0558028bf8579"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\anaconda3\\envs\\rss-hw4\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2227: UserWarning: `max_length` is ignored when `padding`=`True`.\n",
      "  warnings.warn(\"`max_length` is ignored when `padding`=`True`.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/176481 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fc47020ecd6b4646bd8e4b752b2e4a3e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(batch):\n",
    "    tokenized_inputs = tokenizer(batch['reviewText'], padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "    #tokenized_inputs[\"labels\"] = torch.tensor(batch['overall'])\n",
    "    tokenized_inputs[\"labels\"] = torch.tensor(batch['overallInt'])\n",
    "    tokenized_inputs['input_ids'] = tokenized_inputs['input_ids'].squeeze(0)\n",
    "    tokenized_inputs['attention_mask'] = tokenized_inputs['attention_mask'].squeeze(0)\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "train_dataset = Dataset.from_pandas(df_train).map(tokenize, batched=True)\n",
    "test_dataset = Dataset.from_pandas(df_test).map(tokenize, batched=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "train_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "test_dataset.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to compute metrics\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions\n",
    "\n",
    "    # Hard predictions are needed for accuracy, precision, recall, and F1\n",
    "    hard_preds = np.argmax(preds, axis=1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, hard_preds, average='weighted')\n",
    "    acc = accuracy_score(labels, hard_preds)\n",
    "    mae = mean_absolute_error(labels, hard_preds)\n",
    "\n",
    "    # Compute ROC AUC for each class\n",
    "    roc_auc = {}\n",
    "    for i in range(preds.shape[1]):  # Iterate over each class\n",
    "        roc_auc[f\"roc_auc_class_{i}\"] = roc_auc_score((labels == i).astype(int), preds[:, i])\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'mae': mae,\n",
    "        **roc_auc  # This will expand the dictionary to include the roc_auc for each class\n",
    "    }\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained('../../../models/distilbert_amazon_fashion_ver2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.to(device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\AppData\\Local\\Temp\\ipykernel_19620\\4281962671.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_ids = torch.tensor(test_dataset['input_ids'])\n",
      "100%|██████████| 1379/1379 [04:53<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.81      0.74     21276\n",
      "           1       0.43      0.24      0.31     12966\n",
      "           2       0.48      0.51      0.49     19390\n",
      "           3       0.56      0.39      0.46     29979\n",
      "           4       0.84      0.93      0.89     92870\n",
      "\n",
      "    accuracy                           0.73    176481\n",
      "   macro avg       0.60      0.58      0.58    176481\n",
      "weighted avg       0.71      0.73      0.71    176481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create a DataLoader for test_dataset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for batch in tqdm(test_dataloader):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    predictions.extend(outputs.logits.argmax(dim=-1).cpu().numpy())\n",
    "    labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "print(classification_report(labels, predictions))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "([4, 4, 4, 0, 4, 4, 3, 4, 2, 3], [4, 3, 4, 1, 2, 4, 4, 4, 2, 4])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:10], labels[:10]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
